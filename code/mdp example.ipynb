{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open ai frozen lake toy example\n",
    "> solving it using mdp\n",
    "* environment: https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* env.render() : renders the environment\n",
    "* env.reset()  : resets the environment\n",
    "* env.P[state][action] : returns a pair of (prob, next_state, reward, done) list where prop is the probability of the next state for the given state and action pair\n",
    "* There are 16 states\n",
    "* There are 4 actions:\n",
    "    * LEFT = 0\n",
    "    * DOWN = 1\n",
    "    * RIGHT = 2\n",
    "    * UP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3333333333333333, 1, 0.0, False), (0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 5, 0.0, True)]\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "(0, 0.0, False, {'prob': 0.3333333333333333})\n",
      "  (Down)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "print(env.P[1][0])\n",
    "# take a step\n",
    "env.reset()\n",
    "env.render()\n",
    "print(env.step(1))\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3333333333333333, 0, 0.0, False),\n",
       " (0.3333333333333333, 5, 0.0, True),\n",
       " (0.3333333333333333, 2, 0.0, False)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.0, False, {'prob': 0.3333333333333333})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.0, False, {'prob': 0.3333333333333333})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate state values\n",
    "            v(s) = r(s) + v(s+1)\n",
    "            v(s) = r(s) + gamma*sum(prob_i*v(si)) where v(si) potential next states from state s and prob_i is the probability of the next state si from state s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.nS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 12, 0, True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[12][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "states = np.arange(0,16,1)\n",
    "actions = np.arange(0,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]),\n",
       " array([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states,actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of updates = 43\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "v_states = np.zeros(len(states))\n",
    "gamma = 0.9\n",
    "\n",
    "k = 0\n",
    "while k<1000:\n",
    "    delta = 0\n",
    "    for state in states:\n",
    "        vs = 0\n",
    "        \n",
    "        for action in actions: # for a given state loop through actions\n",
    "            for prob,next_state,reward,done in env.P[state][action]: # for a given s and a there are more than one outcome due to frozen ground\n",
    "                vs += (1/len(actions))*prob*(reward + gamma*v_states[next_state])\n",
    "        delta = max(delta,np.abs(v_states[state]-vs))\n",
    "        v_states[state] = vs\n",
    "        \n",
    "    if delta<=0.000000001:\n",
    "        break\n",
    "    \n",
    "    k+=1\n",
    "print('''number of updates = {}'''.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00447726, 0.00422246, 0.01006676, 0.00411822, 0.00672196,\n",
       "       0.        , 0.02633371, 0.        , 0.01867615, 0.05760701,\n",
       "       0.10697195, 0.        , 0.        , 0.13038305, 0.39149016,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "values={}\n",
    "for state,value in enumerate(v_states):\n",
    "    \n",
    "    next_states=[]\n",
    "    for action in actions:\n",
    "        for prob,next_state,reward,done in env.P[state][action]:\n",
    "            next_states.append(next_state)\n",
    "    values[state]=next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 15, 15, 15]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 0, 4, 0, 4, 1, 4, 1, 0, 1, 0, 0],\n",
       " 1: [1, 0, 5, 0, 5, 2, 5, 2, 1, 2, 1, 0],\n",
       " 2: [2, 1, 6, 1, 6, 3, 6, 3, 2, 3, 2, 1],\n",
       " 3: [3, 2, 7, 2, 7, 3, 7, 3, 3, 3, 3, 2],\n",
       " 4: [0, 4, 8, 4, 8, 5, 8, 5, 0, 5, 0, 4],\n",
       " 5: [5, 5, 5, 5],\n",
       " 6: [2, 5, 10, 5, 10, 7, 10, 7, 2, 7, 2, 5],\n",
       " 7: [7, 7, 7, 7],\n",
       " 8: [4, 8, 12, 8, 12, 9, 12, 9, 4, 9, 4, 8],\n",
       " 9: [5, 8, 13, 8, 13, 10, 13, 10, 5, 10, 5, 8],\n",
       " 10: [6, 9, 14, 9, 14, 11, 14, 11, 6, 11, 6, 9],\n",
       " 11: [11, 11, 11, 11],\n",
       " 12: [12, 12, 12, 12],\n",
       " 13: [9, 12, 13, 12, 13, 14, 13, 14, 9, 14, 9, 12],\n",
       " 14: [10, 13, 14, 13, 14, 15, 14, 15, 10, 15, 10, 13],\n",
       " 15: [15, 15, 15, 15]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
